Created on Mon Apr 10 07:07:15 2023

@author: 14632
"""

from langchain.document_loaders import UnstructuredPDFLoader #OnlinePDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

#Load your data
loader = UnstructuredPDFLoader(r"C:\Users\14632\Downloads\Aparicio et al. 2023 02-04-2023.pdf")

# loader = OnlinePDFLoader("https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf")
data = loader.load()
print (f'You have {len(data)} document(s) in your data')
print (f'There are {len(data[0].page_content)} characters in your document')

#Chunk your data up into smaller documents
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(data)
print (f'Now you have {len(texts)} documents')

#Create embeddings of your documents to get ready for semantic search
from langchain.vectorstores import Pinecone #Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
import pinecone
OPENAI_API_KEY = 'ENTER-KEY-HERE...'
PINECONE_API_KEY = 'ENTER-KEY-HERE...'
PINECONE_API_ENV = '...-...-gcp'
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

# initialize pinecone
pinecone.init(
    api_key=PINECONE_API_KEY,  # find at app.pinecone.io
    environment=PINECONE_API_ENV  # next to api key in console
)
index_name = "langchain2"
docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)
query = "What is GPM6a?"
docs = docsearch.similarity_search(query, include_metadata=True)

#Query those docs to get your answer back
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain
llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)
chain = load_qa_chain(llm, chain_type="stuff")
query = "Is PKA or PKC mentioned in the paper?"
docs = docsearch.similarity_search(query, include_metadata=True)
chain.run(input_documents=docs, question=query)
